# -*- coding: utf-8 -*-
"""objtramainv2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bvQwgu0JV_6R4fNWqHyp0Fc0Mpnz5cti
"""

!pip install protobuf==3.20.3
!pip install tensorflow-addons numpy

!pip install tensorflow_gnn

!pip install torch
!pip install torch-geometric
!pip install google-colab

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import os
from PIL import Image
from torch_geometric.nn import GATConv

from google.colab import drive
drive.mount('/content/drive')



class ImageGraphDataset(Dataset):
    def __init__(self, image_dir, graph_dir):
        self.image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.tif')])
        self.graph_files = sorted([os.path.join(graph_dir, f) for f in os.listdir(graph_dir) if f.endswith('.npy')])
        self.min_length = min(len(self.image_files), len(self.graph_files))

    def __len__(self):
        return self.min_length

    def __getitem__(self, idx):
        if idx >= self.min_length:
            raise IndexError("Index out of range")

        image_path = self.image_files[idx]
        graph_path = self.graph_files[idx]

        image = Image.open(image_path).resize((224, 224))
        image = np.array(image).astype(np.float32)
        image = torch.tensor(image).unsqueeze(0)

        graph_data = np.load(graph_path, allow_pickle=True).item()
        x = torch.tensor(graph_data['x'], dtype=torch.float)
        edge_index = torch.tensor(graph_data['edge_index'], dtype=torch.long)
        graph = Data(x=x, edge_index=edge_index)

        label = torch.zeros(1)  # Placeholder label; adjust based on your needs
        return image, graph, label

class SiameseGNN(nn.Module):
    def __init__(self):
        super(SiameseGNN, self).__init__()
        self.convnet = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Flatten()
        )
        self.gnn = GATConv(128, 128)
        self.fc = nn.Sequential(
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 2)
        )

    def forward_once(self, img, graph):
        cnn_features = self.convnet(img)
        gnn_features = self.gnn(graph.x, graph.edge_index)
        combined_features = torch.cat([cnn_features, gnn_features], dim=1)
        return self.fc(combined_features)

    def forward(self, img1, graph1, img2, graph2):
        output1 = self.forward_once(img1, graph1)
        output2 = self.forward_once(img2, graph2)
        return output1, output2

def contrastive_loss(output1, output2, label, margin=1.0):
    euclidean_distance = nn.functional.pairwise_distance(output1, output2)
    loss = label * torch.pow(euclidean_distance, 2) + (1 - label) * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2)
    return loss.mean()

def train(model, dataloader, optimizer, epochs=5):
    model.train()
    loss_values = []
    for epoch in range(epochs):
        epoch_loss = 0
        for img1, graph1, labels in dataloader:
            optimizer.zero_grad()
            output1, output2 = model(img1, graph1, img1, graph1)
            loss = contrastive_loss(output1, output2, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        avg_epoch_loss = epoch_loss / len(dataloader)
        loss_values.append(avg_epoch_loss)
        print(f'Epoch {epoch + 1}, Loss: {avg_epoch_loss}')
    return loss_values

def plot_loss(loss_values):
    plt.plot(loss_values, label='Training Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training Loss Over Epochs')
    plt.legend()
    plt.show()


image_dir = '/content/drive/MyDrive/Colabdata/Fluo-C2DL-Huh7-Training/Fluo-C2DL-Huh7/01'
graph_dir = '/content/drive/MyDrive/Colabdata/Fluo-C2DL-Huh7-Training/Fluo-C2DL-Huh7/01graph'

dataset = ImageGraphDataset(image_dir, graph_dir)
dataloader = DataLoader(dataset, batch_size=2, shuffle=True)

model = SiameseGNN()
optimizer = optim.Adam(model.parameters(), lr=0.0005)

loss_values = train(model, dataloader, optimizer, epochs=5)
plot_loss(loss_values)

class ImageGraphDataset(Dataset):
    def __init__(self, image_dir, graph_dir):
        self.image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.tif')])
        self.graph_files = sorted([os.path.join(graph_dir, f) for f in os.listdir(graph_dir) if f.endswith('.npy')])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image_path = self.image_files[idx]
        graph_path = self.graph_files[idx]

        image = Image.open(image_path).resize((224, 224))
        image = np.array(image).astype(np.float32)
        image = torch.tensor(image).unsqueeze(0)

        graph = np.load(graph_path)
        graph = torch.tensor(graph).float()

        label = torch.zeros(1)  # Placeholder label; adjust based on your needs
        return image, graph, label

class SiameseGNN(nn.Module):
    def __init__(self):
        super(SiameseGNN, self).__init__()
        self.convnet = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=5, activation='relu'),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=5, activation='relu'),
            nn.MaxPool2d(2),
            nn.Flatten()
        )
        self.gnn = GATConv(128, 128)
        self.fc = nn.Sequential(
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 2)
        )

    def forward_once(self, img, graph):
        cnn_features = self.convnet(img)
        gnn_features = self.gnn(graph.x, graph.edge_index)
        combined_features = torch.cat([cnn_features, gnn_features], dim=1)
        return self.fc(combined_features)

    def forward(self, img1, graph1, img2, graph2):
        output1 = self.forward_once(img1, graph1)
        output2 = self.forward_once(img2, graph2)
        return output1, output2

def contrastive_loss(output1, output2, label, margin=1.0):
    euclidean_distance = nn.functional.pairwise_distance(output1, output2)
    loss = label * torch.pow(euclidean_distance, 2) + (1 - label) * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2)
    return loss.mean()

def train(model, dataloader, optimizer, epochs=5):
    model.train()
    for epoch in range(epochs):
        for img1, graph1, labels in dataloader:
            optimizer.zero_grad()
            output1, output2 = model(img1, graph1)
            loss = contrastive_loss(output1, output2, labels)
            loss.backward()
            optimizer.step()
            print(f'Epoch {epoch + 1}, Loss: {loss.item()}')

image_dir = '/content/drive/MyDrive/Colabdata/Fluo-C2DL-Huh7-Training/Fluo-C2DL-Huh7/01'
graph_dir = '/content/drive/MyDrive/Colabdata/Fluo-C2DL-Huh7-Training/Fluo-C2DL-Huh7/01graph'

dataset = ImageGraphDataset(image_dir, graph_dir)
dataloader = DataLoader(dataset, batch_size=2, shuffle=True)

model = SiameseGNN()
optimizer = optim.Adam(model.parameters(), lr=0.0005)

train(model, dataloader, optimizer)







import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import Sequence
from tensorflow_addons.layers import GraphAttention
from tensorflow_addons.losses import contrastive_loss

import numpy as np
import os
from PIL import Image

class ImageGraphSequence(Sequence):
    def __init__(self, image_dir, graph_dir, batch_size):
        self.image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.tif')])
        self.graph_files = sorted([os.path.join(graph_dir, f) for f in os.listdir(graph_dir) if f.endswith('.npy')])
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.image_files) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_images = self.image_files[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_graphs = self.graph_files[idx * self.batch_size:(idx + 1) * self.batch_size]
        images = np.array([np.expand_dims(tf.image.resize(np.array(Image.open(img)), (224, 224)), axis=0)
                           for img in batch_images])
        graphs = [np.load(graph) for graph in batch_graphs]
        labels = np.zeros(len(images))  # Placeholder labels; adjust based on your needs
        return [images, graphs], labels

class SiameseGNN(Model):
    def __init__(self):
        super(SiameseGNN, self).__init__()
        self.convnet = tf.keras.Sequential([
            Conv2D(64, 5, activation='relu'),
            MaxPooling2D(),
            Conv2D(128, 5, activation='relu'),
            MaxPooling2D(),
            Flatten()
        ])
        self.gnn = GraphAttention(128, use_bias=True, kernel_initializer='glorot_uniform')
        self.fc = tf.keras.Sequential([
            Dense(256, activation='relu'),
            Dense(256, activation='relu'),
            Dense(2)
        ])

    def call(self, inputs):
        img, graph = inputs
        cnn_features = self.convnet(img)
        gnn_features = self.gnn(graph)
        combined_features = tf.concat([cnn_features, gnn_features], axis=1)
        return self.fc(combined_features)

    def forward_once(self, img, graph):
        return self.call([img, graph])

    def forward(self, img1, graph1, img2, graph2):
        output1 = self.forward_once(img1, graph1)
        output2 = self.forward_once(img2, graph2)
        return output1, output2

def train(model, dataloader, optimizer, epochs=5):
    for epoch in range(epochs):
        for [img1, graph1], labels in dataloader:
            with tf.GradientTape() as tape:
                output1, output2 = model(img1, graph1)
                loss = contrastive_loss(output1, output2, labels)
            grads = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(grads, model.trainable_variables))
            print(f'Epoch {epoch + 1}, Loss: {loss.numpy()}')

# Adjusted paths for your dataset





image_dir = 'content/drive/MyDrive/Colabdata/Fluo-C2DL-Huh7-Training/Fluo-C2DL-Huh7/01'
graph_dir = 'content/drive/MyDrive/Colabdata/Fluo-C2DL-Huh7-Training/Fluo-C2DL-Huh7/01graph'

dataset = ImageGraphSequence(image_dir, graph_dir, batch_size=2)
model = SiameseGNN()
optimizer = Adam(learning_rate=0.0005)

train(model, dataset, optimizer)

